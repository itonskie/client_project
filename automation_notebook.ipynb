{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db552856-9e65-4b6a-87cc-69553bc5c9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from automation_script import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b883cf-3964-4b2f-805f-56279e60d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from automation_script import *\n",
    "\n",
    "automation = AutomationProcess()\n",
    "automation.add_input_path('inputs/UpworkSampleCSV.csv')\\\n",
    "            .add_output_path('outputs/')\\\n",
    "            .automate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce539dfc-a4f7-416a-874d-f43b5697f401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2183fa-a736-4bad-8f8c-2ab8b0b3bc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pipeline Finished Processing'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automation = AutomationProcess()\n",
    "automation.add_input_path('inputs/UpworkSampleCSV.csv')\\\n",
    "            .add_output_path('outputs/')\\\n",
    "            .automate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552acb4f-0387-4608-bf0e-653fe4f4603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_addresses = os.listdir('outputs/')\n",
    "\n",
    "def df_generator(files):\n",
    "    for i in files:\n",
    "        yield pd.read_csv(f'outputs/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2300f9d-9f34-41a3-8d5c-89f8f58066df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = next(df_generator(files_addresses))\n",
    "df2 = next(df_generator(files_addresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398da796-bbc4-48fa-b864-4415b9779f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>address</th>\n",
       "      <th>orgid</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>chain_name</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>in_chain</th>\n",
       "      <th>in_search</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Category3</th>\n",
       "      <th>Category4</th>\n",
       "      <th>Category5</th>\n",
       "      <th>Category6</th>\n",
       "      <th>Category7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CID:5097641582142782286</td>\n",
       "      <td>PhotoWorks Interactive Photobooth Rentals of S...</td>\n",
       "      <td>1550 dell ave, campbell, ca 95008</td>\n",
       "      <td>photoworksinteractive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>(800) 990-8445</td>\n",
       "      <td>photoworksinteractive.com</td>\n",
       "      <td>photoworksinteractive</td>\n",
       "      <td>Photoworks Interactive</td>\n",
       "      <td>...</td>\n",
       "      <td>-121.955669</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Photography Service</td>\n",
       "      <td>Party Supply</td>\n",
       "      <td>Printing &amp; Copy Shop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                listing_id                                      business_name  \\\n",
       "0  CID:5097641582142782286  PhotoWorks Interactive Photobooth Rentals of S...   \n",
       "\n",
       "                             address                  orgid  Rating  \\\n",
       "0  1550 dell ave, campbell, ca 95008  photoworksinteractive     5.0   \n",
       "\n",
       "   Rating Count           phone                    website  \\\n",
       "0             7  (800) 990-8445  photoworksinteractive.com   \n",
       "\n",
       "                  domain              chain_name  ...         lon  in_chain  \\\n",
       "0  photoworksinteractive  Photoworks Interactive  ... -121.955669      True   \n",
       "\n",
       "   in_search            Category1     Category2             Category3  \\\n",
       "0       True  Photography Service  Party Supply  Printing & Copy Shop   \n",
       "\n",
       "  Category4  Category5  Category6  Category7  \n",
       "0       NaN        NaN        NaN        NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de93f97-22ae-4724-8424-03cc520f7f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>address</th>\n",
       "      <th>orgid</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>chain_name</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>in_chain</th>\n",
       "      <th>in_search</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Category3</th>\n",
       "      <th>Category4</th>\n",
       "      <th>Category5</th>\n",
       "      <th>Category6</th>\n",
       "      <th>Category7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CID:5097641582142782286</td>\n",
       "      <td>PhotoWorks Interactive Photobooth Rentals of S...</td>\n",
       "      <td>1550 dell ave, campbell, ca 95008</td>\n",
       "      <td>photoworksinteractive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>(800) 990-8445</td>\n",
       "      <td>photoworksinteractive.com</td>\n",
       "      <td>photoworksinteractive</td>\n",
       "      <td>Photoworks Interactive</td>\n",
       "      <td>...</td>\n",
       "      <td>-121.955669</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Photography Service</td>\n",
       "      <td>Party Supply</td>\n",
       "      <td>Printing &amp; Copy Shop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                listing_id                                      business_name  \\\n",
       "0  CID:5097641582142782286  PhotoWorks Interactive Photobooth Rentals of S...   \n",
       "\n",
       "                             address                  orgid  Rating  \\\n",
       "0  1550 dell ave, campbell, ca 95008  photoworksinteractive     5.0   \n",
       "\n",
       "   Rating Count           phone                    website  \\\n",
       "0             7  (800) 990-8445  photoworksinteractive.com   \n",
       "\n",
       "                  domain              chain_name  ...         lon  in_chain  \\\n",
       "0  photoworksinteractive  Photoworks Interactive  ... -121.955669      True   \n",
       "\n",
       "   in_search            Category1     Category2             Category3  \\\n",
       "0       True  Photography Service  Party Supply  Printing & Copy Shop   \n",
       "\n",
       "  Category4  Category5  Category6  Category7  \n",
       "0       NaN        NaN        NaN        NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a2d32-87f6-43ad-a61d-3677f91aa665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the Excel writer object\n",
    "writer = pd.ExcelWriter('combined_dataframes.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Define a function to write a dataframe to the Excel file with its name as a header\n",
    "def write_dataframe(df, sheet_name):\n",
    "    df.to_excel(writer, sheet_name=sheet_name, startrow=1, header=False)\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    worksheet.write_string(0, 0, sheet_name)\n",
    "\n",
    "# Loop through your dataframes and write them to the Excel file\n",
    "for i, df in enumerate([df1, df2, df3, df4, df5, df6, df7, df8]):\n",
    "    write_dataframe(df, 'Dataframe {}'.format(i+1))\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7f816a-4f57-40be-a833-f0e89b4557c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define a class to hold automation related data and methods\n",
    "class Automation:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_path = None\n",
    "        self.output_path = None\n",
    "        self.data = None\n",
    "        self.unique_addresses = None\n",
    "\n",
    "    # Set the input file path\n",
    "    def set_input_path(self, input_path):\n",
    "        self.input_path = input_path\n",
    "\n",
    "    # Set the output file path\n",
    "    def set_output_path(self, output_path):\n",
    "        self.output_path = output_path\n",
    "\n",
    "    # Load data into the object\n",
    "    def load_data(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    # Set unique addresses in the object\n",
    "    def set_unique_addresses(self, addresses):\n",
    "        self.unique_addresses = addresses\n",
    "\n",
    "\n",
    "# Define a class to hold automation process related methods\n",
    "class AutomationProcess:\n",
    "    \n",
    "    # Instantiate Automation\n",
    "    def __init__(self):\n",
    "        self.automation = Automation()\n",
    "        \n",
    "    # Set the input file path in the Automation object\n",
    "    def add_input_path(self, input_path):\n",
    "        self.automation.set_input_path(input_path)\n",
    "        return self\n",
    "\n",
    "    # Set the output file path in the Automation object\n",
    "    def add_output_path(self, output_path):\n",
    "        self.automation.set_output_path(output_path)\n",
    "        return self\n",
    "\n",
    "    # Load data into the Automation object\n",
    "    def load_dataframe_from_csv(self):\n",
    "        # Check if the input file path exists and is a valid file\n",
    "        if not self.automation.input_path or not os.path.isfile(self.automation.input_path):\n",
    "            raise ValueError(\"Input path is not set or is not a valid file.\")\n",
    "        # Load the csv file into the object\n",
    "        self.automation.load_data(pd.read_csv(self.automation.input_path))\n",
    "\n",
    "    # Standardize the address column in the data\n",
    "    def standardize_address(self):\n",
    "        # Convert the address column to lowercase, strip whitespace, and remove extra spaces\n",
    "        self.automation.data['address'] = self.automation.data['address'].str.lower().str.strip().str.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "    # Set unique addresses in the Automation object\n",
    "    def get_unique_addresses(self):\n",
    "        self.automation.set_unique_addresses(self.automation.data['address'].unique())\n",
    "\n",
    "    # Sort a dataframe by the rating column\n",
    "    def sort_by_ratings(self, df):\n",
    "        return df.sort_values(by='Rating', ascending=False)\n",
    "    \n",
    "    # Save the data in a csv file\n",
    "    def save_data(self, df, address):\n",
    "        filename = f\"{self.automation.output_path + address}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "    # Define a function to write a dataframe to the Csv file with its name as a header\n",
    "    def write_dataframe(self, df, address):\n",
    "        # open a file object in append mode\n",
    "        with open('output.csv', 'a') as f:\n",
    "            # write the first dataframe to the file\n",
    "            if f.tell() != 0:\n",
    "                f.write('\\n')\n",
    "            f.write(f'{address}\\n')\n",
    "            df.to_csv(f, index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    # Iterate through unique addresses and update categories\n",
    "    def iterate_addresses(self):\n",
    "        df = self.automation.data \n",
    "        for address in self.automation.unique_addresses:\n",
    "            # Sort the dataframe by rating for a specific address\n",
    "            df_filtered = df.loc[df['address'] == address]\n",
    "            if df_filtered.shape == (1, len(df.columns)):\n",
    "                # If there is only one row, directly save it to CSV and continue with the next address\n",
    "                self.save_data(df_filtered, address)\n",
    "                self.write_dataframe(df_filtered, address)\n",
    "                continue\n",
    "\n",
    "            # Sort the dataframe by rating for a specific address\n",
    "            df_sorted = self.sort_by_ratings(df_filtered)\n",
    "            \n",
    "            # Set the in_search column to False for all but the first row\n",
    "            df_sorted.iloc[1:, df_sorted.columns.get_loc('in_search')] = False\n",
    "            \n",
    "            # Reset the index to start from 0\n",
    "            df_sorted = df_sorted.reset_index(drop=True)\n",
    "            \n",
    "            # Get the category values for all but the first row\n",
    "            values = df_sorted['Category1'][1:].tolist()\n",
    "            \n",
    "            # Get all the category column names\n",
    "            columns = [col for col in df_sorted.columns if col.startswith('Category')]\n",
    "            \n",
    "            # Update category columns with values from subsequent rows\n",
    "            for col in columns:\n",
    "                if not values:\n",
    "                    break\n",
    "                if pd.isna(df_sorted.loc[0, col]):\n",
    "                    df_sorted.loc[0, col] = values.pop(0)\n",
    "            \n",
    "            # Save the updated data to a CSV file\n",
    "            self.save_data(df_sorted, address)\n",
    "            self.write_dataframe(df_sorted, address)\n",
    "        \n",
    "        return 'Pipeline Finished Processing'\n",
    "\n",
    "    # Runs the Automation process\n",
    "    def automate(self):\n",
    "        self.load_dataframe_from_csv()\n",
    "        self.standardize_address()\n",
    "        self.get_unique_addresses()\n",
    "        self.iterate_addresses()\n",
    "        return 'Pipeline Finished Processing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d75b02-a5f4-4e1c-9e83-f2dd00a98451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create some example dataframes\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Jane', 'Jack', 'Jill'], 'Age': [35, 27, 42, 29]})\n",
    "df2 = pd.DataFrame({'Country': ['USA', 'China', 'Japan', 'Germany'], 'Population': [328.2, 1400, 126.3, 83.2], 'GDP': [21.4, 14.1, 5.2, 4.2]})\n",
    "\n",
    "# open a file object in append mode\n",
    "with open('output.csv', 'a') as f:\n",
    "    # write the first dataframe to the file\n",
    "    f.write('Dataframe 1\\n')\n",
    "    df1.to_csv(f, index=False)\n",
    "    \n",
    "    # write the second dataframe to the file\n",
    "    f.write('Dataframe 2\\n')\n",
    "    df2.to_csv(f, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258beda6-5b81-4395-906a-1c50794913b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 7, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# end of file\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# read the dataframe from the file\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# add the dataframe to the list with the given label\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_list\u001b[38;5;241m.\u001b[39mappend((label, df))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 7, saw 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the data from the file into a list of dataframes\n",
    "df_list = []\n",
    "with open('output.csv', 'r') as f:\n",
    "    while True:\n",
    "        # read the label for the next dataframe\n",
    "        label = f.readline().strip()\n",
    "        if not label:\n",
    "            break  # end of file\n",
    "        \n",
    "        # read the dataframe from the file\n",
    "        df = pd.read_csv(f)\n",
    "        \n",
    "        # add the dataframe to the list with the given label\n",
    "        df_list.append((label, df))\n",
    "\n",
    "# print the contents of the dataframes\n",
    "for label, df in df_list:\n",
    "    print(f\"{label}:\\n{df}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf855ddc-62fb-4f04-b2d4-97f21a22a252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
